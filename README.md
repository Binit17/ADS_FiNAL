# Topic Modeling Using Latent Dirichlet Allocation, Latent Semantic Analysis, and BERT Transformer & Its Applications

## Overview

This project explores the use of three powerful techniques for topic modeling:

1. **Latent Dirichlet Allocation (LDA)** - A generative probabilistic model leveraging the Dirichlet and multinomial distributions.
2. **Latent Semantic Analysis (LSA)** - A dimensionality reduction approach based on singular value decomposition (SVD).
3. **BERTopic Pipeline** - A modern topic modeling approach utilizing BERT embeddings and clustering techniques.

## Datasets

We used three datasets to evaluate the topic modeling methods:

1. [Dataset 1](<add link>)
2. [Dataset 2](<add link>)
3. [Dataset 3](<add link>)

## Learning Outcomes

Throughout the project, we gained insights into:

- **Dirichlet and Multinomial Distributions**: Fundamental components of LDA.
- **Generative Probabilistic Models**: How LDA generates topics and documents.
- **Singular-Value Decomposition (SVD)**: Used for dimensionality reduction in LSA.
- **BERT Embeddings**: Capturing semantic relationships between words and documents.
- **UMAP for Dimensionality Reduction**: Effective visualization and preprocessing for clustering.
- **Clustering Techniques**:
  - **k-means clustering**
  - **HDBSCAN clustering**
- **Topic Modeling Evaluation Metrics**:
  - **Coherence Score**: Measuring the interpretability of topics.
  - **Topic Diversity**: Assessing topic representation across documents.
  - **Silhouette Score**: Evaluating clustering quality.

## Results

<Add brief summary or leave placeholder for results>

## Output Visualizations

Below are some sample visualizations from the project:

### LDA Model Output

<Insert image or description here>

### LSA Model Output

<Insert image or description here>

### BERTopic Model Output

<Insert image or description here>

---

Stay tuned for more updates and detailed discussions in this repository!
